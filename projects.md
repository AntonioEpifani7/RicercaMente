
## THE HISTORY
| Year | Name | Authors | Topic | Description | Impact | Media | Link | More | 
| --- | --- | --- | --- | --- | --- | --- | --- | --- |
| 1928 | On the Theory of Games of Strategy | John von Neumann | MATH | Introduced the concept of extensive-form games and the minimax theorem, establishing foundational principles for game theory. | Pioneering work that laid the groundwork for game theory, influencing diverse fields from economics to AI decision-making algorithms. | Contributions to the Theory of Games | [Link to Paper](https://cs.uwaterloo.ca/~y328yu/classics/vonNeumann.pdf) | |
| 1948 | A Mathematical Theory of Communication | Claude Shannon |PROGRAMMING| Proposed the fundamental concepts of information theory, including entropy, channel capacity, and the source coding theorem. Revolutionized the understanding of communication and laid the groundwork for data compression and error correction. | Pioneering work that significantly influenced information theory, data science, and communication systems. | The Bell System Technical Journal | [Link to Paper](http://math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf) | |
| 1950 | Computing Machinery and Intelligence | Alan Turing | AI | Introduced the concept of the Turing Test, a benchmark for determining a machine's ability to exhibit intelligent behavior indistinguishable from that of a human. | Pioneering work that laid the foundation for discussions on machine intelligence and artificial general intelligence (AGI). | Mind | [Link to Paper](https://academic.oup.com/mind/article/LIX/236/433/986238)|  |
| 1984 | Classification and Regression Trees | Leo Breiman | AI | Introduced the fundamental concepts of decision trees, a method widely used in data science | Fundamental contribution that has shaped the approach to data analysis through decision trees. | Journal of the American Statistical Association | [Link to paper](https://www.taylorfrancis.com/books/mono/10.1201/9781315139470/classification-regression-trees-leo-breiman) | |
| 1997 | Long Short-Term Memory | Sepp Hochreiter and Jürgen Schmidhuber | AI | Introduces Long Short-Term Memory (LSTM), a type of Recurrent Neural Network (RNN) architecture designed to overcome the vanishing gradient problem in traditional RNN. | LSTM address the challenge of learning dependencies over extended time periods, leading to more effective and efficient training on sequential tasks. | Neural Computation | [Link to paper](https://www.researchgate.net/publication/13853244_Long_Short-term_Memory) |  |
| 1998 | Gradient-based learning applied to document recognition (CNN/GTN) | Yann Lecun, Léon Bottou, Yoshua Bengio and Patrick Haffner | AI | This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. | It is deployed commercially and reads several million cheques per day. | IEEE | [Link to Paper](https://ieeexplore.ieee.org/abstract/document/726791/authors#authors) | |
| 2009 | ImageNet Large Scale Visual Recognition Challenge | Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, Alexander C. Berg, Li Fei-Fei | Visual Recognition, Challenge, Datasets | Provides a comprehensive overview of the ImageNet Large Scale Visual Recognition Challenge (ILSVRC), a benchmark in the field of object category classification and detection using large-scale datasets. The challenge has been conducted annually since 2010 and has garnered participation from over fifty institutions. | Advancements in Object Recognition, Large scale standardization for computer vision research datasets, Development of Deep Learning (Mostly CNNs) | Springer | [Link to Paper](https://arxiv.org/pdf/1409.0575.pdf)|  |
| 2012 | ImageNet Classification with Deep Convolutional Neural Networks | Alex Krizhevsky, Ilya Sutskever, Geoffrey E. Hinton | AI | Proposed the use of a Deep CNN architecture (also known as AlexNet) for image classification. Introduced important techniques such as the use of ReLU activation function, data augmentation and dropouts to prevent overfitting and training on multiple GPUs. The architecture proposed achieved a top-5 error rate of 16,4% on the ImageNet dataset and won the ILSVRC-2012 competition. | The introduction of deeper CNN led to an important turning point in computer vision tasks. AlexNet outperformed existing models at the time and established new standards in the evolution of CNN architectures. | Advances in neural information processing systems | [Link to Paper](https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf) | |
| 2014 | Very Deep Convolutional Networks For Large-Scale Image Recognition | Karen Simonyan, Andrew Zisserman | AI | This paper analysed the impact of increased depth of CNN on image classification. The VGGNet improved the state-of-art performance using architectures with up to 19 layers and 3x3 convolutional kernel filters, which are smaller than the filters used in previous models. | This paper confirmed the importance of depth in visual representation and inspired the design of the following models. | International Conference on Learning Representations (ICLR) | [Link to Paper](https://arxiv.org/pdf/1409.1556.pdf) | |
| 2016 | Mastering the Game of Go with Deep Neural Networks and Tree Search | David Silver et al. | AI | Presented AlphaGo, a model that defeated the European Go champion by 5 games to 0. It uses [Monte Carlo Tree Search (MCTS)](https://hal.inria.fr/inria-00116992/document) to compute its next move, running simulations of possible outcomes. | Demonstrated that AI can tackle complex challenges and achieve excellence in strategic games | Nature | [Link to Paper](https://storage.googleapis.com/deepmind-media/alphago/AlphaGoNaturePaper.pdf) |  |
| 2017 | Attention is All You Need | Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin | AI | Revealed the transformer, a new neural network that is a significant milestone in modern Deep Learning models. Shaped the way we think about and approach NLP problems. | Has had a profound impact on NLP research and applications | NIPS | [Link to Paper](https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf) |  |
